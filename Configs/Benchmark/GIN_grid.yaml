epochs: [ 100 ]
batch_size: [ 16, 32 ]
emb_dim: [ 16, 32, 64 ]
drop_out: [ 0.0, 0.5 ]
num_layer: [ 2,3,4,5,8 ]
lr: [ 0.0001, 0.001 ]
virtual_node: [ 0 ]
pooling: [ "sum", "mean" ]
lr_schedule_patience: [ 10000 ]
model: [ "GIN" ]
transform_k_wl: [ 0, 3 ]
k_wl_turbo: [ 0 ]
tracking: [ 1 ]
drop_feat: [ 1 ]
filter_data_max_graph_size: [ 10 ]