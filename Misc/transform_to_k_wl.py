import pickle
from collections import defaultdict
from copy import deepcopy
from itertools import product, combinations
from statistics import mean

import networkx as nx
import torch
import torch_geometric
from matplotlib import pyplot as plt
from torch import transpose, stack, mode, tensor, cat, zeros, empty, int32
from torch.nn.functional import pad
from torch_geometric.data import Data
from torch_geometric.transforms import BaseTransform


class TransforToKWl(BaseTransform):
    def __init__(self, k: int):
        if not 2 <= k <= 3:
            raise NotImplementedError('k-WL: k can be only 2 or 3 at the moment')
        self.k = k
        self.range_k = list(range(k))
        self.matrices = {}
        for k in range(30):
            self.matrices[k] = (self.create_empty_graph(k))

        self.average_num_of_vertices = 0
        self.average_num_of_new_vertices = 0
        self.vertices_num = defaultdict(int)
        self.processed_num = 0

    def create_empty_graph(self, n):
        if n == 0:
            return [], [[]]
        all_combinations = list(product(list(range(n)), repeat=self.k))
        # all_combinations = list(combinations(list(range(n)), self.k))
        edges = [[], []]
        edge_attributes = []
        for i, c1 in enumerate(all_combinations):
            for j, c2 in enumerate(all_combinations):
                # the adjacency is simple. If the new vertices share old vertices except one.
                # The number is the position where they differ
                common = self.has_common(c1, c2)
                if common is not None:
                    edges[0].append(i)
                    edges[1].append(j)
                    edge_attributes.append(common)

        if len(all_combinations) != n ** self.k:
            raise ValueError('numbers dont add up', len(all_combinations), n, self.k)
        return all_combinations, edges, edge_attributes

    def has_common(self, c1, c2):
        diff_num = 0
        diff_pos = None
        for i in self.range_k:
            if c1[i] != c2[i]:
                diff_num += 1
                diff_pos = i + 1
        if diff_num != 1:
            return None
        return diff_pos

    def create_adjacency_from_graph(self, graph, size):
        adj = [[None for j in range(size)] for i in range(size)]
        attrs = graph['edge_attr'].tolist()
        for i, x in enumerate(transpose(graph['edge_index'], 0, 1)):
            adj[x[0]][x[1]] = attrs[i]
        return adj

    def graph_to_k_wl_graph(self, graph):
        vert_num = graph['num_nodes']
        num_edges = graph.edge_attr.shape[0]
        # TODO this excludes any graph larger than 60 nodes from calculation
        if vert_num < 2 or num_edges == 0 or vert_num > 60:
            # if vert_num > 10:
            #     plt.clf()
            #     g = torch_geometric.utils.to_networkx(graph, to_undirected=True)
            #     nx.draw(g)
            #     plt.savefig(f'pictures/graph_{sum(self.vertices_num.values())}.png')
            if num_edges == 0:
                graph.edge_attr = empty((0, graph.edge_attr.shape[1] + 1), dtype=int32)
            else:
                graph.edge_attr = pad(graph.edge_attr, pad=(1, 0, 0, 0), value=0)

            graph.x = pad(graph.x, pad=(1, 0, 0, 0), value=0)
            return graph
        len_edge_attr = graph.edge_attr.shape[1]
        if vert_num < 30:
            if vert_num not in self.matrices:
                self.matrices[vert_num] = self.create_empty_graph(vert_num)
            all_combinations, new_edges, new_edge_attr = deepcopy(self.matrices[vert_num])
        else:
            all_combinations, new_edges, new_edge_attr = self.create_empty_graph(vert_num)

        old_adj = self.create_adjacency_from_graph(graph, vert_num)
        new_x = [0] * len(all_combinations)
        for i in range(len(new_edge_attr)):
            c1 = all_combinations[new_edges[0][i]]
            c2 = all_combinations[new_edges[1][i]]
            # edge attributes are hard. This will include median of all the edges that
            # were between any of the vertexes from the two subgraphs. It can be remade to just include the stack.
            # The first attribute is the number generated by the k_WL algorithm form the function has_common
            selected_attrs = [tensor(old_adj[x[0]][x[1]]) for x in
                              combinations(set(c1 + c2), 2) if
                              old_adj[x[0]][x[1]] is not None]

            # in case there was no edge between any of the graph vertices
            if len(selected_attrs) == 0:
                new_edge_attr[i] = cat((tensor([new_edge_attr[i]]),
                                        zeros((len_edge_attr), dtype=int32)))
            else:
                new_edge_attr[i] = cat((tensor([new_edge_attr[i]]),
                                        mode(stack(selected_attrs),
                                             dim=0).values))

        for i, c in enumerate(all_combinations):
            # works only for K==2 and K==3
            # sum of number of edges in the subgraph
            # for K larger than 3, I would suggest using hash from WL algorithm on each small subgraph
            # Using bool to detect where edge has value and where None is.
            k_x = [sum([bool(old_adj[c[j - 1]][c[j]]) for j in range(len(c))])]
            # adding all vertex features from the vertex in the subgraph using mode to keep the dimensionality.
            new_x[i] = cat((tensor(k_x), mode(stack([graph.x[j] for j in c]), dim=0).values), 0)

        graph.x = stack(new_x)
        graph.num_nodes = len(all_combinations)

        if len(new_edges[0]) > 0:
            graph.edge_attr = stack(new_edge_attr)
            graph.edge_index = tensor(new_edges)
        else:
            graph.edge_attr = empty((0, len_edge_attr + 1), dtype=int32)
            graph.edge_index = empty((2, 0), dtype=int32)
        self.average_num_of_vertices = mean((self.average_num_of_vertices, vert_num))
        self.average_num_of_new_vertices = mean((self.average_num_of_new_vertices, vert_num ** self.k))
        return graph

    def __call__(self, data: Data) -> Data:
        self.processed_num += 1
        if self.processed_num % 100 == 0:
            print(f'transform to k-WL -- done {self.processed_num}')
        self.vertices_num[data['num_nodes']] += 1
        return self.graph_to_k_wl_graph(data)

    def __repr__(self) -> str:
        return (f'{self.__class__.__name__}(k={self.k})')

    def __del__(self):
        print('number of vertices in graphs', self.vertices_num)
        print('average_num_of_vertices', self.average_num_of_vertices)
        print('average_num_of_new_vertices', self.average_num_of_new_vertices)

    def split_graph(self, graph):
        pass
